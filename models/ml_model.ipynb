{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from itertools import cycle\n",
    "import seaborn as sns\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import signal\n",
    "from contextlib import contextmanager\n",
    "import time\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "ignore_warnings = True  \n",
    "if ignore_warnings:\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "# Attention Layer\n",
    "class AttentionLayer(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name='attention_weight',\n",
    "                                 shape=(input_shape[-1], 1),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(name='attention_bias',\n",
    "                                 shape=(input_shape[1], 1),\n",
    "                                 initializer='zeros',\n",
    "                                 trainable=True)\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        # e = tanh(xW + b)\n",
    "        e = tf.tanh(tf.keras.backend.dot(x, self.W) + self.b)\n",
    "        # a = softmax(e)\n",
    "        a = tf.keras.backend.softmax(e, axis=1)\n",
    "        # output = sum(a * x)\n",
    "        output = tf.keras.backend.sum(a * x, axis=1)\n",
    "        return output\n",
    "\n",
    "# Model Architecture\n",
    "def build_lstm_attention_model(input_shape, output_classes):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Bi-directional LSTM Layer\n",
    "    model.add(layers.Bidirectional(layers.LSTM(128, return_sequences=True), input_shape=input_shape))\n",
    "\n",
    "    # Attention Layer\n",
    "    model.add(AttentionLayer())\n",
    "\n",
    "    # Additional layers as per your requirement\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(output_classes, activation='softmax'))  # Assuming 3 triage levels\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "class TFNeuralNetwork: \n",
    "    def __init__(self, input_shape, output_classes, lstm=False):\n",
    "        if lstm:\n",
    "            self.model = build_lstm_attention_model(input_shape, output_classes)\n",
    "        else:\n",
    "            self.model = create_tf_neural_network(input_shape, output_classes)\n",
    "\n",
    "    def fit(self, X_train, y_train, epochs=10, batch_size=32):\n",
    "        self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions = self.model.predict(X_test)\n",
    "        return predictions.argmax(axis=1)\n",
    "    \n",
    "    def predict_proba(self, X_test):\n",
    "        return self.model.predict(X_test)\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        loss, accuracy = self.model.evaluate(X_test, y_test)\n",
    "        return accuracy\n",
    "\n",
    "def create_tf_neural_network(input_shape, output_classes):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(output_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "class MLModel:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.training_time = None\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        start_time = time.time()\n",
    "        self.model.fit(X_train, y_train)\n",
    "        end_time = time.time()\n",
    "        self.training_time = end_time - start_time\n",
    "\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        self.y_pred = self.model.predict(X_test)\n",
    "        return self.y_pred\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        predictions = self.predict(X_test)\n",
    "        predict_proba = self.model.predict_proba(X_test)\n",
    "        \n",
    "        #true_labels = np.argmax(y_test, axis=1)\n",
    "        report = classification_report(y_test, predictions, target_names=['Red', 'Yellow','Green'])  # Update target names based on your classes\n",
    "        acc = accuracy_score(y_test, predictions)\n",
    "        rec = recall_score(y_test, predictions, average='macro')\n",
    "        prec = precision_score(y_test, predictions, average='macro')\n",
    "        f1 = f1_score(y_test, predictions, average='macro')\n",
    "        auc = roc_auc_score(y_test, predict_proba, multi_class='ovo')\n",
    "        return {\n",
    "            'predictions': predictions,\n",
    "            'predict_proba': predict_proba,\n",
    "            'report': report,\n",
    "            'accuracy': acc,\n",
    "            'recall': rec,\n",
    "            'precision': prec,\n",
    "            'f1_score': f1,\n",
    "            'auc': auc,\n",
    "            'training_time': self.training_time,\n",
    "            'model_object':self\n",
    "        }\n",
    "    \n",
    "    \n",
    "    def plot_confusion_matrix(self, X_test, y_test, experiment_name):\n",
    "        # Confusion matrix plot logic\n",
    "        cm = confusion_matrix(y_test, self.y_pred)\n",
    "        # Plot the confusion matrix\n",
    "        plt.title('Confusion Matrix')\n",
    "        #plt.figure(figsize=(10,7))\n",
    "        sns.heatmap(cm, annot=True, fmt='d')\n",
    "        classes = ['Red', 'Yellow','Green']\n",
    "        plt.xticks(np.arange(3), classes, rotation=45)\n",
    "        plt.yticks(np.arange(3), classes)\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        if not os.path.exists(experiment_name):\n",
    "            os.makedirs(experiment_name)\n",
    "        plt.savefig(f\"{experiment_name}/confusion_matrix.png\")\n",
    "\n",
    "    def plot_roc(self, X_test, y_test, experiment_name):\n",
    "        # Binarize the output\n",
    "        y = label_binarize(y_test, classes=[0, 1, 2])\n",
    "        n_classes = y.shape[1]\n",
    "\n",
    "        # Compute ROC curve and ROC area for each class\n",
    "        y_pred = self.model.predict_proba(X_test)\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        for i in range(n_classes):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y[:, i], y_pred[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        classes = ['Red', 'Yellow','Green']\n",
    "        # Plot all ROC curves\n",
    "        plt.figure()\n",
    "        colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "        for i, color in zip(range(n_classes), colors):\n",
    "            plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                    label='ROC curve of class {0} (area = {1:0.2f})'.format(classes[i], roc_auc[i]))\n",
    "\n",
    "        plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "        plt.xlim([-0.05, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate (FPR)')\n",
    "        plt.ylabel('True Positive Rate (TPR)')\n",
    "        plt.title('Receiver Operating Characteristic (ROC)')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        if not os.path.exists(experiment_name):\n",
    "            os.makedirs(experiment_name)\n",
    "        plt.savefig(f\"{experiment_name}/roc.png\")\n",
    "\n",
    "\n",
    "    def save_results(self, results, experiment_name):\n",
    "        if not os.path.exists(experiment_name):\n",
    "            os.makedirs(experiment_name)\n",
    "        with open(f\"{experiment_name}/results.pkl\", 'wb') as file:\n",
    "            pickle.dump(results, file)\n",
    "\n",
    "    def feature_importance(self, feature_names, experiment_name):\n",
    "        if hasattr(self.model, 'feature_importances_'):\n",
    "            # For models with feature_importances_ attribute (e.g., RandomForest)\n",
    "            importances = self.model.feature_importances_\n",
    "        elif hasattr(self.model, 'coef_'):\n",
    "            # For models with coef_ attribute (e.g., LogisticRegression)\n",
    "            importances = np.abs(self.model.coef_[0])\n",
    "        else:\n",
    "            print(\"Model does not have feature_importances_ or coef_ attribute\")\n",
    "            return\n",
    "        feature_names_length = min(15, len(feature_names))\n",
    "        indices = np.argsort(importances)[::-1][:feature_names_length]\n",
    "        # Plot the feature importances\n",
    "        plt.figure(figsize=(12, 6))  # Increase the plot size\n",
    "        plt.title(\"Feature Importances\")\n",
    "        plt.bar(range(feature_names_length), importances[indices], color=\"b\", align=\"center\")\n",
    "        # Rotate feature names for better visibility\n",
    "        plt.xticks(range(feature_names_length), [feature_names[i] for i in indices], rotation=45, ha=\"right\")\n",
    "        # Adjust the font size and alignment if necessary\n",
    "        plt.tick_params(axis='x', which='major', labelsize=9)  # Decrease label font size if needed\n",
    "        plt.tight_layout()  # Adjust the padding between and around subplots.\n",
    "        plt.show()\n",
    "        if not os.path.exists(experiment_name):\n",
    "            os.makedirs(experiment_name)\n",
    "        plt.savefig(f\"{experiment_name}/feature_importance.png\")\n",
    "\n",
    "def read_data():\n",
    "    # read data section\n",
    "    #####\n",
    "    df_biobert = #***\n",
    "    df_labels = #***\n",
    "    df_numerical_vars = #***\n",
    "    df_categorical_vars = #***\n",
    "    df_categorical_vars_raw = #***\n",
    "    df_target = #***\n",
    "    y_one_hot_labels = #***\n",
    "    y_int_labels = #***\n",
    "    return df_biobert, df_labels, df_numerical_vars, df_categorical_vars, df_categorical_vars_raw, df_target, y_one_hot_labels, y_int_labels\n",
    "df_biobert, df_labels, df_numerical_vars, df_categorical_vars, df_categorical_vars_raw, df_target, y_one_hot_labels, y_int_labels = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'numerical', 'categorical', 'text_embeddings', \n",
    "#MLModel(RandomForestClassifier())\n",
    "# 'GradientBoostingClassifier'\n",
    "# MLModel(GradientBoostingClassifier())\n",
    "data_count = \"whole_data\"\n",
    "text_embedding_methods = ['BoW', 'Word2Vec100', 'Word2Vec768','BioBERT']\n",
    "feature_set = ['all_features', 'all_features_except_text_embeddings', 'all_features_except_categorical', 'all_features_except_numerical']\n",
    "model_names = ['LogisticRegression', 'TFNeuralNetwork','RandomForestClassifier', 'XGBClassifier']\n",
    "for text_embedding_method in text_embedding_methods:\n",
    "    if text_embedding_method == 'BoW':\n",
    "        df_biobert =  pd.read_pickle('../pickles/input_data/bow_emb.pkl')\n",
    "        df_biobert = pd.DataFrame.sparse.from_spmatrix(df_biobert)\n",
    "    elif text_embedding_method == 'Word2Vec100':\n",
    "        df_biobert =  pd.read_pickle('../pickles/input_data/w2vec_dim100_emb.pkl')\n",
    "    elif text_embedding_method == 'Word2Vec768':\n",
    "        df_biobert =  pd.read_pickle('../pickles/input_data/w2vec_768dim_emb.pkl')\n",
    "    else:\n",
    "        df_biobert = pd.read_pickle('../../../code/temp_data_v2/sentence_embeddings/BioBERT-mnli-snli-scinli-scitail-mednli-stsb-format-3.pickle')\n",
    "    for features in feature_set:\n",
    "        if features == 'numerical':\n",
    "            X_train, X_test, y_train, y_test = train_test_split(df_numerical_vars, y_int_labels, test_size=0.2, random_state=42)\n",
    "        elif features == 'categorical':\n",
    "            X_train, X_test, y_train, y_test = train_test_split(df_categorical_vars, y_int_labels, test_size=0.2, random_state=42)\n",
    "        elif features == 'text_embeddings':\n",
    "            X_train, X_test, y_train, y_test = train_test_split(pd.DataFrame(df_biobert), y_int_labels, test_size=0.2, random_state=42)\n",
    "        elif features == 'all_features':\n",
    "            X_train, X_test, y_train, y_test = train_test_split(pd.concat([df_numerical_vars, df_categorical_vars,pd.DataFrame(df_biobert)], axis=1), y_int_labels, test_size=0.2, random_state=42)\n",
    "        elif features == 'all_features_except_text_embeddings':\n",
    "            X_train, X_test, y_train, y_test = train_test_split(pd.concat([df_numerical_vars, df_categorical_vars], axis=1), y_int_labels, test_size=0.2, random_state=42)\n",
    "        elif features == 'all_features_except_categorical':\n",
    "            X_train, X_test, y_train, y_test = train_test_split(pd.concat([df_numerical_vars,pd.DataFrame(df_biobert)], axis=1), y_int_labels, test_size=0.2, random_state=42)\n",
    "        elif features == 'all_features_except_numerical':\n",
    "            X_train, X_test, y_train, y_test = train_test_split(pd.concat([df_categorical_vars,pd.DataFrame(df_biobert)], axis=1), y_int_labels, test_size=0.2, random_state=42)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid feature set\")\n",
    "        X_train.columns = X_train.columns.astype(str)\n",
    "        X_test.columns = X_test.columns.astype(str)\n",
    "        X_train = X_train.astype('float32')\n",
    "        X_test = X_test.astype('float32')\n",
    "        i = 0\n",
    "        for model in [MLModel(LogisticRegression()), MLModel(TFNeuralNetwork(X_train.shape[1], 3)), MLModel(RandomForestClassifier()), MLModel(GradientBoostingClassifier())]:\n",
    "            model.train(X_train, y_train)\n",
    "            results = model.evaluate(X_test, y_test)\n",
    "            print(results)\n",
    "            experiment_name = 'experiment_{3}_{0}_n_{1}_text_embd_{2})'.format(model_names[i],data_count,text_embedding_method,features)\n",
    "            model.plot_roc(X_test, y_test, \"../results/\" + experiment_name)\n",
    "            model.save_results(results, \"../results/\" + experiment_name)\n",
    "            model.plot_confusion_matrix(X_test, y_test, \"../results/\" + experiment_name)\n",
    "            model.feature_importance(X_train.columns, \"../results/\" + experiment_name)\n",
    "            i += 1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
