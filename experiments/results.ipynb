{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meyildirim/Desktop/Notebooks/Learning/master-thesis/etl/.venv/lib/python3.8/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from itertools import cycle\n",
    "import seaborn as sns\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import re\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "ignore_warnings = True\n",
    "if ignore_warnings:\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "class TFNeuralNetwork:\n",
    "    def __init__(self, input_shape, output_classes):\n",
    "        self.model = create_tf_neural_network(input_shape, output_classes)\n",
    "\n",
    "    def fit(self, X_train, y_train, epochs=10, batch_size=32):\n",
    "        self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions = self.model.predict(X_test)\n",
    "        return predictions.argmax(axis=1)\n",
    "\n",
    "    def predict_proba(self, X_test):\n",
    "        return self.model.predict(X_test)\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        loss, accuracy = self.model.evaluate(X_test, y_test)\n",
    "        return accuracy\n",
    "def create_tf_neural_network(input_shape, output_classes):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(output_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "class MLModel:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.training_time = None\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        start_time = time.time()\n",
    "        self.model.fit(X_train, y_train)\n",
    "        end_time = time.time()\n",
    "        self.training_time = end_time - start_time\n",
    "\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        self.y_pred = self.model.predict(X_test)\n",
    "        return self.y_pred\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        predictions = self.predict(X_test)\n",
    "        predict_proba = self.model.predict_proba(X_test)\n",
    "\n",
    "        #true_labels = np.argmax(y_test, axis=1)\n",
    "        report = classification_report(y_test, predictions, target_names=['Red', 'Yellow','Green'])  # Update target names based on your classes\n",
    "        acc = accuracy_score(y_test, predictions)\n",
    "        rec = recall_score(y_test, predictions, average='macro')\n",
    "        prec = precision_score(y_test, predictions, average='macro')\n",
    "        f1 = f1_score(y_test, predictions, average='macro')\n",
    "        auc = roc_auc_score(y_test, predict_proba, multi_class='ovo')\n",
    "        return {\n",
    "            'predictions': predictions,\n",
    "            'predict_proba': predict_proba,\n",
    "            'report': report,\n",
    "            'accuracy': acc,\n",
    "            'recall': rec,\n",
    "            'precision': prec,\n",
    "            'f1_score': f1,\n",
    "            'auc': auc,\n",
    "            'training_time': self.training_time,\n",
    "            'model_object':self\n",
    "        }\n",
    "\n",
    "\n",
    "    def plot_confusion_matrix(self, X_test, y_test, experiment_name):\n",
    "        # Confusion matrix plot logic\n",
    "        cm = confusion_matrix(y_test, self.y_pred)\n",
    "        # Plot the confusion matrix\n",
    "        plt.title('Confusion Matrix')\n",
    "        #plt.figure(figsize=(10,7))\n",
    "        sns.heatmap(cm, annot=True, fmt='d')\n",
    "        classes = ['Red', 'Yellow','Green']\n",
    "        plt.xticks(np.arange(3), classes, rotation=45)\n",
    "        plt.yticks(np.arange(3), classes)\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        if not os.path.exists(experiment_name):\n",
    "            os.makedirs(experiment_name)\n",
    "        plt.savefig(f\"{experiment_name}/confusion_matrix.png\")\n",
    "\n",
    "    def plot_roc(self, X_test, y_test, experiment_name):\n",
    "        # Binarize the output\n",
    "        y = label_binarize(y_test, classes=[0, 1, 2])\n",
    "        n_classes = y.shape[1]\n",
    "\n",
    "        # Compute ROC curve and ROC area for each class\n",
    "        y_pred = self.model.predict_proba(X_test)\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        for i in range(n_classes):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y[:, i], y_pred[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        classes = ['Red', 'Yellow','Green']\n",
    "        # Plot all ROC curves\n",
    "        plt.figure()\n",
    "        colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "        for i, color in zip(range(n_classes), colors):\n",
    "            plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                    label='ROC curve of class {0} (area = {1:0.2f})'.format(classes[i], roc_auc[i]))\n",
    "\n",
    "        plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "        plt.xlim([-0.05, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate (FPR)')\n",
    "        plt.ylabel('True Positive Rate (TPR)')\n",
    "        plt.title('Receiver Operating Characteristic (ROC)')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        if not os.path.exists(experiment_name):\n",
    "            os.makedirs(experiment_name)\n",
    "        plt.savefig(f\"{experiment_name}/roc.png\")\n",
    "\n",
    "\n",
    "    def save_results(self, results, experiment_name):\n",
    "        if not os.path.exists(experiment_name):\n",
    "            os.makedirs(experiment_name)\n",
    "        with open(f\"{experiment_name}/results.pkl\", 'wb') as file:\n",
    "            pickle.dump(results, file)\n",
    "\n",
    "    def feature_importance(self, feature_names, experiment_name):\n",
    "        if hasattr(self.model, 'feature_importances_'):\n",
    "            # For models with feature_importances_ attribute (e.g., RandomForest)\n",
    "            importances = self.model.feature_importances_\n",
    "        elif hasattr(self.model, 'coef_'):\n",
    "            # For models with coef_ attribute (e.g., LogisticRegression)\n",
    "            importances = np.abs(self.model.coef_[0])\n",
    "        else:\n",
    "            print(\"Model does not have feature_importances_ or coef_ attribute\")\n",
    "            return\n",
    "        feature_names_length = min(15, len(feature_names))\n",
    "        indices = np.argsort(importances)[::-1][:feature_names_length]\n",
    "        # Plot the feature importances\n",
    "        plt.figure(figsize=(12, 6))  # Increase the plot size\n",
    "        plt.title(\"Feature Importances\")\n",
    "        plt.bar(range(feature_names_length), importances[indices], color=\"b\", align=\"center\")\n",
    "        # Rotate feature names for better visibility\n",
    "        plt.xticks(range(feature_names_length), [feature_names[i] for i in indices], rotation=45, ha=\"right\")\n",
    "        # Adjust the font size and alignment if necessary\n",
    "        plt.tick_params(axis='x', which='major', labelsize=9)  # Decrease label font size if needed\n",
    "        plt.tight_layout()  # Adjust the padding between and around subplots.\n",
    "        plt.show()\n",
    "        if not os.path.exists(experiment_name):\n",
    "            os.makedirs(experiment_name)\n",
    "        plt.savefig(f\"{experiment_name}/feature_importance.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "# All files and directories ending with .txt and that don't begin with a dot:\n",
    "list_of_experiments = ## **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with /Users/meyildirim/Desktop/Notebooks/Learning/master-thesis/etl/code/experiments/results/experiment_categorical_TFNeuralNetwork_n_whole_data_text_embd_BioBERT)\n",
      "Error with /Users/meyildirim/Desktop/Notebooks/Learning/master-thesis/etl/code/experiments/results/experiment_text_embeddings_TFNeuralNetwork_n_whole_data_text_embd_BioBERT)\n",
      "Error with /Users/meyildirim/Desktop/Notebooks/Learning/master-thesis/etl/code/experiments/results/experiment_numerical_TFNeuralNetwork_n_whole_data_text_embd_BioBERT)\n",
      "experiment_id_1: {'feature_set': 'text_embeddings', 'algorithm': 'LogisticRegression', 'text_embedding_method': 'BioBERT'}\n",
      "experiment_id_2: {'feature_set': 'categorical', 'algorithm': 'LogisticRegression', 'text_embedding_method': 'BioBERT'}\n",
      "experiment_id_3: {'feature_set': 'categorical', 'algorithm': 'TFNeuralNetwork', 'text_embedding_method': 'BioBERT'}\n",
      "experiment_id_4: {'feature_set': 'text_embeddings', 'algorithm': 'TFNeuralNetwork', 'text_embedding_method': 'BioBERT'}\n",
      "experiment_id_5: {'feature_set': 'all_features_except_categorical', 'algorithm': 'LogisticRegression', 'text_embedding_method': 'BERT-multilingual'}\n",
      "experiment_id_6: {'feature_set': 'numerical', 'algorithm': 'TFNeuralNetwork', 'text_embedding_method': 'BioBERT'}\n",
      "experiment_id_7: {'feature_set': 'numerical', 'algorithm': 'LogisticRegression', 'text_embedding_method': 'BioBERT'}\n",
      "experiment_id_8: {'feature_set': 'text_embeddings', 'algorithm': 'RandomForestClassifier', 'text_embedding_method': 'BioBERT'}\n",
      "experiment_id_9: {'feature_set': 'categorical', 'algorithm': 'GradientBoostingClassifier', 'text_embedding_method': 'BioBERT'}\n",
      "experiment_id_10: {'feature_set': 'numerical', 'algorithm': 'GradientBoostingClassifier', 'text_embedding_method': 'BioBERT'}\n",
      "experiment_id_11: {'feature_set': 'numerical', 'algorithm': 'RandomForestClassifier', 'text_embedding_method': 'BioBERT'}\n",
      "experiment_id_12: {'feature_set': 'text_embeddings', 'algorithm': 'GradientBoostingClassifier', 'text_embedding_method': 'BioBERT'}\n",
      "experiment_id_13: {'feature_set': 'categorical', 'algorithm': 'RandomForestClassifier', 'text_embedding_method': 'BioBERT'}\n",
      "experiment_id_14: {'feature_set': 'all_features', 'algorithm': 'LogisticRegression', 'text_embedding_method': 'BioBERT'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# List of filenames\n",
    "list_of_experiments = ## **\n",
    "\n",
    "\n",
    "# Function to extract information from filename\n",
    "def extract_info(filename):\n",
    "    # Adjusted pattern to handle feature sets with underscores\n",
    "    pattern = r'experiment_([^_]+(?:_[^_]+)*)_([^_]+)_n_whole_data_text_embd_([^)]+)'\n",
    "    match = re.search(pattern, filename)\n",
    "    if match:\n",
    "        return {\n",
    "            'feature_set': match.group(1),\n",
    "            'algorithm': match.group(2),\n",
    "            'text_embedding_method': match.group(3)\n",
    "        }\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Main dictionary to store experiments\n",
    "experiments = {}\n",
    "results = {}\n",
    "\n",
    "# Process each file and add to dictionary\n",
    "for idx, filename in enumerate(list_of_experiments, start=1):\n",
    "    info = extract_info(filename)\n",
    "    if info:\n",
    "        experiments[f'experiment_id_{idx}'] = info\n",
    "    try:\n",
    "        with open(f\"{filename}/results.pkl\", 'rb') as file:\n",
    "            results[f'experiment_id_{idx}'] = pickle.load(file)\n",
    "    except:\n",
    "        print(f\"Error with {filename}\")\n",
    "\n",
    "\n",
    "# Print the dictionary\n",
    "for key, value in experiments.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a pandas df from two dictionary\n",
    "experiment_df = pd.DataFrame.from_dict(experiments, orient='index')\n",
    "for key, value in results.items():\n",
    "    experiment_df.loc[key, 'accuracy'] = value['accuracy'] \n",
    "    experiment_df.loc[key, 'recall'] = value['recall'] \n",
    "    experiment_df.loc[key, 'precision'] = value['precision'] \n",
    "    experiment_df.loc[key, 'f1_score'] = value['f1_score'] \n",
    "    experiment_df.loc[key, 'auc'] = value['auc'] \n",
    "    experiment_df.loc[key, 'training_time'] = value['training_time'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_set</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>text_embedding_method</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc</th>\n",
       "      <th>training_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>experiment_id_1</th>\n",
       "      <td>text_embeddings</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>BioBERT</td>\n",
       "      <td>0.750473</td>\n",
       "      <td>0.493956</td>\n",
       "      <td>0.579187</td>\n",
       "      <td>0.493469</td>\n",
       "      <td>0.797833</td>\n",
       "      <td>48.644255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_id_2</th>\n",
       "      <td>categorical</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>BioBERT</td>\n",
       "      <td>0.626468</td>\n",
       "      <td>0.413242</td>\n",
       "      <td>0.567896</td>\n",
       "      <td>0.408861</td>\n",
       "      <td>0.657623</td>\n",
       "      <td>20.617074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_id_3</th>\n",
       "      <td>categorical</td>\n",
       "      <td>TFNeuralNetwork</td>\n",
       "      <td>BioBERT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_id_4</th>\n",
       "      <td>text_embeddings</td>\n",
       "      <td>TFNeuralNetwork</td>\n",
       "      <td>BioBERT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_id_5</th>\n",
       "      <td>all_features_except_categorical</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>BERT-multilingual</td>\n",
       "      <td>0.661230</td>\n",
       "      <td>0.414378</td>\n",
       "      <td>0.428579</td>\n",
       "      <td>0.410473</td>\n",
       "      <td>0.644333</td>\n",
       "      <td>82.021492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_id_6</th>\n",
       "      <td>numerical</td>\n",
       "      <td>TFNeuralNetwork</td>\n",
       "      <td>BioBERT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_id_7</th>\n",
       "      <td>numerical</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>BioBERT</td>\n",
       "      <td>0.660938</td>\n",
       "      <td>0.413941</td>\n",
       "      <td>0.428464</td>\n",
       "      <td>0.409955</td>\n",
       "      <td>0.645610</td>\n",
       "      <td>8.702550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_id_8</th>\n",
       "      <td>text_embeddings</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>BioBERT</td>\n",
       "      <td>0.755051</td>\n",
       "      <td>0.522298</td>\n",
       "      <td>0.631265</td>\n",
       "      <td>0.541520</td>\n",
       "      <td>0.779925</td>\n",
       "      <td>669.116558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_id_9</th>\n",
       "      <td>categorical</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>BioBERT</td>\n",
       "      <td>0.625772</td>\n",
       "      <td>0.431581</td>\n",
       "      <td>0.576212</td>\n",
       "      <td>0.427168</td>\n",
       "      <td>0.659377</td>\n",
       "      <td>78.368037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_id_10</th>\n",
       "      <td>numerical</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>BioBERT</td>\n",
       "      <td>0.689048</td>\n",
       "      <td>0.468128</td>\n",
       "      <td>0.612808</td>\n",
       "      <td>0.488399</td>\n",
       "      <td>0.737237</td>\n",
       "      <td>99.347659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_id_11</th>\n",
       "      <td>numerical</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>BioBERT</td>\n",
       "      <td>0.683816</td>\n",
       "      <td>0.463173</td>\n",
       "      <td>0.571701</td>\n",
       "      <td>0.477358</td>\n",
       "      <td>0.715089</td>\n",
       "      <td>46.622916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_id_12</th>\n",
       "      <td>text_embeddings</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>BioBERT</td>\n",
       "      <td>0.738603</td>\n",
       "      <td>0.509483</td>\n",
       "      <td>0.625539</td>\n",
       "      <td>0.529486</td>\n",
       "      <td>0.788411</td>\n",
       "      <td>16497.450187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_id_13</th>\n",
       "      <td>categorical</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>BioBERT</td>\n",
       "      <td>0.625633</td>\n",
       "      <td>0.428218</td>\n",
       "      <td>0.569999</td>\n",
       "      <td>0.423565</td>\n",
       "      <td>0.654186</td>\n",
       "      <td>21.506826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_id_14</th>\n",
       "      <td>all_features</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>BioBERT</td>\n",
       "      <td>0.720025</td>\n",
       "      <td>0.468685</td>\n",
       "      <td>0.599757</td>\n",
       "      <td>0.469300</td>\n",
       "      <td>0.732444</td>\n",
       "      <td>148.745675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      feature_set                   algorithm  \\\n",
       "experiment_id_1                   text_embeddings          LogisticRegression   \n",
       "experiment_id_2                       categorical          LogisticRegression   \n",
       "experiment_id_3                       categorical             TFNeuralNetwork   \n",
       "experiment_id_4                   text_embeddings             TFNeuralNetwork   \n",
       "experiment_id_5   all_features_except_categorical          LogisticRegression   \n",
       "experiment_id_6                         numerical             TFNeuralNetwork   \n",
       "experiment_id_7                         numerical          LogisticRegression   \n",
       "experiment_id_8                   text_embeddings      RandomForestClassifier   \n",
       "experiment_id_9                       categorical  GradientBoostingClassifier   \n",
       "experiment_id_10                        numerical  GradientBoostingClassifier   \n",
       "experiment_id_11                        numerical      RandomForestClassifier   \n",
       "experiment_id_12                  text_embeddings  GradientBoostingClassifier   \n",
       "experiment_id_13                      categorical      RandomForestClassifier   \n",
       "experiment_id_14                     all_features          LogisticRegression   \n",
       "\n",
       "                 text_embedding_method  accuracy    recall  precision  \\\n",
       "experiment_id_1                BioBERT  0.750473  0.493956   0.579187   \n",
       "experiment_id_2                BioBERT  0.626468  0.413242   0.567896   \n",
       "experiment_id_3                BioBERT       NaN       NaN        NaN   \n",
       "experiment_id_4                BioBERT       NaN       NaN        NaN   \n",
       "experiment_id_5      BERT-multilingual  0.661230  0.414378   0.428579   \n",
       "experiment_id_6                BioBERT       NaN       NaN        NaN   \n",
       "experiment_id_7                BioBERT  0.660938  0.413941   0.428464   \n",
       "experiment_id_8                BioBERT  0.755051  0.522298   0.631265   \n",
       "experiment_id_9                BioBERT  0.625772  0.431581   0.576212   \n",
       "experiment_id_10               BioBERT  0.689048  0.468128   0.612808   \n",
       "experiment_id_11               BioBERT  0.683816  0.463173   0.571701   \n",
       "experiment_id_12               BioBERT  0.738603  0.509483   0.625539   \n",
       "experiment_id_13               BioBERT  0.625633  0.428218   0.569999   \n",
       "experiment_id_14               BioBERT  0.720025  0.468685   0.599757   \n",
       "\n",
       "                  f1_score       auc  training_time  \n",
       "experiment_id_1   0.493469  0.797833      48.644255  \n",
       "experiment_id_2   0.408861  0.657623      20.617074  \n",
       "experiment_id_3        NaN       NaN            NaN  \n",
       "experiment_id_4        NaN       NaN            NaN  \n",
       "experiment_id_5   0.410473  0.644333      82.021492  \n",
       "experiment_id_6        NaN       NaN            NaN  \n",
       "experiment_id_7   0.409955  0.645610       8.702550  \n",
       "experiment_id_8   0.541520  0.779925     669.116558  \n",
       "experiment_id_9   0.427168  0.659377      78.368037  \n",
       "experiment_id_10  0.488399  0.737237      99.347659  \n",
       "experiment_id_11  0.477358  0.715089      46.622916  \n",
       "experiment_id_12  0.529486  0.788411   16497.450187  \n",
       "experiment_id_13  0.423565  0.654186      21.506826  \n",
       "experiment_id_14  0.469300  0.732444     148.745675  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
